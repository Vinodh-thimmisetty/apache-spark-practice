{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927bc397",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T17:29:04.932969Z",
     "start_time": "2021-10-19T17:29:04.925236Z"
    }
   },
   "source": [
    "# Practice Apache Spark (PySpark)\n",
    "\n",
    "[Learning Source](https://www.linkedin.com/company/justenough-spark/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf8b099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T17:36:32.571506Z",
     "start_time": "2021-10-19T17:36:24.321006Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Oct-19-2021 - WINDOW Functions\n",
    "\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType,DoubleType, StringType\n",
    "from pyspark.sql.functions import col, row_number,avg, sum, min, max, rank, dense_rank, percent_rank, ntile, cume_dist, lag, lead\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Spark Question Bank - JustEnough Spark(Linkedin)\").getOrCreate()\n",
    "\n",
    "df_schema = StructType([\n",
    "    StructField(\"Country\", StringType(), True ),\n",
    "    StructField(\"StateName\", StringType(), True ),\n",
    "    StructField(\"OverallPopulationInMillion\", DoubleType(), True ),\n",
    "    StructField(\"VaccinatedPopulationInMillion\", DoubleType(), True )    \n",
    "])\n",
    "\n",
    "df_data = [\n",
    "    ('USA', 'California', 39.55, 28.89),\n",
    "    ('USA', 'Seattle', 0.79, 0.76),\n",
    "    ('USA', 'Texas', 29.25, 15.17),\n",
    "    ('India', 'Maharastra', 12.24, 9.2),\n",
    "    ('India', 'Kerala', 3.5, 3.7),\n",
    "    ('India', 'Andhra Pradesh', 5.2, 4.7), \n",
    "    ('India', 'TamilNadu', 7.5, 5.3),\n",
    "    ('UK', 'London', 8.96, 7.23),\n",
    "    ('UK', 'Liverpool', 0.96, 0.87),\n",
    "    ('UK', 'Machester', 2.96, 2.03),\n",
    "    ('China', 'Beijing', 20.89, 19.37), \n",
    "    ('France', 'Paris', 2.18, 1.99), \n",
    "]\n",
    "\n",
    "vaccines_df = spark.createDataFrame(df_data, df_schema)\n",
    "\n",
    "vaccines_df = vaccines_df.withColumn('VaccinationPercentage',\n",
    "                                     round((col('VaccinatedPopulationInMillion')/col('OverallPopulationInMillion')*100), 2))\n",
    "\n",
    "vaccines_df.printSchema()\n",
    "\n",
    "print(' >>>>>  WINDOW RANKING FUNCTIONS  START <<<<< ') \n",
    "\n",
    "# ROW_NUM\n",
    "    \n",
    "print(' >>>>>  ROW_NUM Plain SQL  <<<<< ')\n",
    "vaccines_df.createOrReplaceTempView('VACCINATION_VW')\n",
    "spark.sql('select *, row_number() over(order by StateName) as ROW_NUM from VACCINATION_VW').show()\n",
    "spark.sql('select *, row_number() over(partition by Country order by StateName) as ROW_NUM from VACCINATION_VW').show()\n",
    "\n",
    "print(' >>>>>  ROW_NUM Spark SQL  <<<<< ')\n",
    "row_window_spec = Window.orderBy('StateName')\n",
    "vaccines_df.withColumn('ROW_NUM', row_number().over(row_window_spec)).show()\n",
    "row_window_spec = Window.partitionBy('Country').orderBy('StateName')\n",
    "vaccines_df.withColumn('ROW_NUM', row_number().over(row_window_spec)).show()\n",
    "\n",
    "\n",
    "# RANK\n",
    "print(' >>>>>  RANK Plain SQL <<<<< ')\n",
    "vaccines_df.createOrReplaceTempView('VACCINATION_VW')\n",
    "spark.sql('select *, rank() over(order by VaccinationPercentage) as RANK from VACCINATION_VW').show()\n",
    "spark.sql('select *, rank() over(partition by Country order by VaccinationPercentage desc) as RANK from VACCINATION_VW').show()\n",
    "    \n",
    "print(' >>>>>  RANK Spark SQL  <<<<< ')\n",
    "rank_window_spec = Window.orderBy(col('VaccinationPercentage'))\n",
    "vaccines_df.withColumn('RANK', rank().over(rank_window_spec)).show()\n",
    "rank_window_spec = Window.partitionBy('Country').orderBy(col('VaccinationPercentage').desc())\n",
    "vaccines_df.withColumn('RANK', rank().over(rank_window_spec)).show() \n",
    "\n",
    "\n",
    "\n",
    "# DENSE RANK\n",
    "print(' >>>>> DENSE RANK Plain SQL <<<<< ')\n",
    "vaccines_df.createOrReplaceTempView('VACCINATION_VW')\n",
    "spark.sql('select *, dense_rank() over(order by VaccinationPercentage) as DENSE_RANK from VACCINATION_VW').show()\n",
    "spark.sql('select *, dense_rank() over(partition by Country order by VaccinationPercentage desc) as DENSE_RANK from VACCINATION_VW').show()\n",
    "    \n",
    "print(' >>>>> DENSE RANK Spark SQL  <<<<< ')\n",
    "rank_window_spec = Window.orderBy(col('VaccinationPercentage'))\n",
    "vaccines_df.withColumn('DENSE_RANK', dense_rank().over(rank_window_spec)).show()\n",
    "rank_window_spec = Window.partitionBy('Country').orderBy(col('VaccinationPercentage').desc())\n",
    "vaccines_df.withColumn('DENSE_RANK', dense_rank().over(rank_window_spec)).show() \n",
    "\n",
    "# PERCENT RANK\n",
    "print(' >>>>> PERCENT RANK Plain SQL <<<<< ')\n",
    "vaccines_df.createOrReplaceTempView('VACCINATION_VW')\n",
    "spark.sql('select Country, StateName, VaccinationPercentage, percent_rank() over(order by VaccinationPercentage) as PERCENT_RANK from VACCINATION_VW').show()\n",
    "spark.sql('select Country, StateName, VaccinationPercentage, percent_rank() over(partition by Country order by VaccinationPercentage desc) as PERCENT_RANK from VACCINATION_VW').show()\n",
    "    \n",
    "print(' >>>>> PERCENT RANK Spark SQL  <<<<< ')\n",
    "rank_window_spec = Window.orderBy(col('VaccinationPercentage'))\n",
    "vaccines_df.withColumn('PERCENT_RANK', percent_rank().over(rank_window_spec)).show()\n",
    "rank_window_spec = Window.partitionBy('Country').orderBy(col('VaccinationPercentage').desc())\n",
    "vaccines_df.withColumn('PERCENT_RANK', percent_rank().over(rank_window_spec)).show() \n",
    "\n",
    "\n",
    "# NTILE\n",
    "print(' >>>>> NTILE Plain SQL <<<<< ')\n",
    "vaccines_df.createOrReplaceTempView('VACCINATION_VW')\n",
    "spark.sql('select Country, StateName, VaccinationPercentage, ntile(5) over(order by VaccinationPercentage) as NTILE from VACCINATION_VW').show()\n",
    "spark.sql('select Country, StateName, VaccinationPercentage, ntile(5) over(partition by Country order by VaccinationPercentage desc) as NTILE from VACCINATION_VW').show()\n",
    "    \n",
    "print(' >>>>> NTILE Spark SQL  <<<<< ')\n",
    "rank_window_spec = Window.orderBy(col('VaccinationPercentage'))\n",
    "vaccines_df.withColumn('NTILE', ntile(5).over(rank_window_spec)).show()\n",
    "rank_window_spec = Window.partitionBy('Country').orderBy(col('VaccinationPercentage').desc())\n",
    "vaccines_df.withColumn('NTILE', ntile(5).over(rank_window_spec)).show() \n",
    "\n",
    "\n",
    "print(' >>>>>  WINDOW RANKING FUNCTIONS  END <<<<< ') \n",
    "\n",
    "\n",
    "print(' >>>>>  WINDOW ANALYTIC FUNCTIONS  START <<<<< ')\n",
    "\n",
    "# cume_dist\n",
    "print(' >>>>> cume_dist Plain SQL <<<<< ')\n",
    "vaccines_df.createOrReplaceTempView('VACCINATION_VW')\n",
    "spark.sql('select Country, StateName, VaccinationPercentage, cume_dist() over(order by Country) as cume_dist from VACCINATION_VW').show()\n",
    "spark.sql('select Country, StateName, VaccinationPercentage, cume_dist() over(partition by Country order by StateName) as cume_dist from VACCINATION_VW').show()\n",
    "    \n",
    "print(' >>>>> cume_dist Spark SQL  <<<<< ')\n",
    "rank_window_spec = Window.orderBy('Country')\n",
    "vaccines_df.withColumn('cume_dist', cume_dist().over(rank_window_spec)).show()\n",
    "rank_window_spec = Window.partitionBy('Country').orderBy(col('StateName'))\n",
    "vaccines_df.withColumn('cume_dist', cume_dist().over(rank_window_spec)).show() \n",
    "\n",
    "# LAG & LEAD\n",
    "print(' >>>>> LAG & LEAD Plain SQL <<<<< ')\n",
    "vaccines_df.createOrReplaceTempView('VACCINATION_VW')\n",
    "spark.sql('select Country, StateName, VaccinationPercentage, lag(Country) over(order by Country) as LAG, lead(Country) over(order by Country) as LEAD from VACCINATION_VW').show()\n",
    "spark.sql('select Country, StateName, VaccinationPercentage, lag(Country, 1) over(partition by Country order by StateName) as LAG,lead(Country, 1) over(partition by Country order by StateName) as LEAD from VACCINATION_VW').show()\n",
    "    \n",
    "print(' >>>>> LAG & LEAD Spark SQL  <<<<< ')\n",
    "rank_window_spec = Window.orderBy('Country')\n",
    "vaccines_df.withColumn('LAG', lag('Country').over(rank_window_spec)).withColumn('LEAD', lead('Country').over(rank_window_spec)).show()\n",
    "rank_window_spec = Window.partitionBy('Country').orderBy(col('StateName'))\n",
    "vaccines_df.withColumn('LAG', lag(col('Country'), 1).over(rank_window_spec)).withColumn('LEAD', lead(col('Country'), 1).over(rank_window_spec)).show() \n",
    "\n",
    "\n",
    "print(' >>>>>  WINDOW ANALYTIC FUNCTIONS  END <<<<< ')\n",
    "\n",
    "\n",
    "print(' >>>>>  WINDOW AGGREGATE FUNCTIONS  START <<<<< ') \n",
    "\n",
    "print(' >>>>> AGGREGATE Plain SQL <<<<< ')\n",
    "vaccines_df.createOrReplaceTempView('VACCINATION_VW') \n",
    "spark.sql('select distinct Country, min(VaccinationPercentage) over(partition by Country order by Country) as MIN_VACC, max(VaccinationPercentage) over(partition by Country order by Country) as MAX_VACC, avg(VaccinationPercentage) over(partition by Country order by Country) as AVG_VACC from VACCINATION_VW').show()\n",
    "    \n",
    "print(' >>>>> AGGREGATE Spark SQL  <<<<< ')\n",
    "rank_window_spec = Window.partitionBy('Country').orderBy(col('Country').desc())\n",
    "vaccines_df.withColumn('MIN_VACC', min(col('VaccinationPercentage')).over(rank_window_spec)).withColumn('MAX_VACC', max('VaccinationPercentage').over(rank_window_spec)).withColumn('AVG_VACC', avg('VaccinationPercentage').over(rank_window_spec)).select('Country', 'MIN_VACC', 'MAX_VACC', 'AVG_VACC').distinct().show() \n",
    "\n",
    "\n",
    "print(' >>>>>  WINDOW AGGREGATE FUNCTIONS  END <<<<< ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13cd178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "107px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
